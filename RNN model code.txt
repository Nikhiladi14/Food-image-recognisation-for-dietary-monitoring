import zipfile

# download zip file of pizza_steak images
!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip
zip_file = zipfile.ZipFile("pizza_steak.zip", "r")
zip_file.extractall()
zip_file.close()
!ls pizza_steak
!ls pizza_steak/test/
!ls pizza_steak/test/pizza/
import os

# walkthrough pizza_steak directory and list number of files
for dirpath, dirnames, filenames in os.walk("pizza_steak"):
  print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")
num_pizza_images_test = len(os.listdir("pizza_steak/test/pizza"))
num_pizza_images_test
import pathlib
import numpy as np
data_dir = pathlib.Path("pizza_steak/train/") # turn training path into python path
class_names = np.array(sorted([item.name for item in data_dir.glob('*')])) # create a list of class_names from subdirectories
print(class_names)
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random

def view_random_image(target_dir, target_class):
  # setup target directory
  target_folder = target_dir+target_class

  # get a random image path
  random_image = random.sample(os.listdir(target_folder), 1)

  # read the image and plot it
  img = mpimg.imread(target_folder + "/" + random_image[0])
  plt.imshow(img)
  plt.title(target_class)
  plt.axis("off")

  print(f"Image shape: {img.shape}") # the shape of the image

  return img
plt.figure()
plt.subplot(1,2,1)
pizza_img = view_random_image(target_dir="pizza_steak/train/",
                        target_class="pizza")

plt.subplot(1,2,2)
steak_img = view_random_image("pizza_steak/train/", "steak")
pizza_img
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, LSTM, GlobalAveragePooling2D, Reshape
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# set the seed
tf.random.set_seed(42)

# preprocess data
train_datagen = ImageDataGenerator(rescale=1./255)
valid_datagen = ImageDataGenerator(rescale=1./255)

# setup the train and test directory paths
train_dir = "pizza_steak/train/"
test_dir = "pizza_steak/test/"

# import data from directories and turn it into batches
train_data = train_datagen.flow_from_directory(train_dir,
                                               batch_size=32,
                                               target_size=(224,224),
                                               class_mode="binary",
                                               seed=42)

valid_data = valid_datagen.flow_from_directory(test_dir,
                                               batch_size=32,
                                               target_size=(224,224),
                                               class_mode="binary",
                                               seed=42)

# Define RNN model
input_shape = (224, 224, 3)

# Input layer
inputs = Input(shape=input_shape)

# Feature extraction layers
x = Conv2D(filters=32, kernel_size=3, activation='relu')(inputs)
x = MaxPooling2D(pool_size=2)(x)
x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)
x = MaxPooling2D(pool_size=2)(x)

# Reduce spatial dimensions using GlobalAveragePooling2D
x = GlobalAveragePooling2D()(x)

# Reshape the feature maps to fit LSTM input shape
x = Reshape((1, -1))(x)

# LSTM layer
x = LSTM(64)(x)

# Dense layers for classification
x = Dense(128, activation='relu')(x)
outputs = Dense(1, activation='sigmoid')(x)

# Create RNN model
model_rnn = Model(inputs=inputs, outputs=outputs)

# Compile the model
model_rnn.compile(loss="binary_crossentropy",
                   optimizer=Adam(),
                   metrics=["accuracy"])

# Fit the model
history_rnn = model_rnn.fit(train_data,
                            epochs=1,
                            steps_per_epoch=len(train_data),
                            validation_data=valid_data,
                            validation_steps=len(valid_data))