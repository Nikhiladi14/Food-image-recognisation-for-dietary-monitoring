import zipfile

# download zip file of pizza_steak images
!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip
zip_file = zipfile.ZipFile("pizza_steak.zip", "r")
zip_file.extractall()
zip_file.close()
!ls pizza_steak
!ls pizza_steak/test/
!ls pizza_steak/test/pizza/
import os 

# walkthrough pizza_steak directory and list number of files
for dirpath, dirnames, filenames in os.walk("pizza_steak"):
  print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")
num_pizza_images_test = len(os.listdir("pizza_steak/test/pizza"))
num_pizza_images_test
import pathlib
import numpy as np
data_dir = pathlib.Path("pizza_steak/train/") # turn training path into python path
class_names = np.array(sorted([item.name for item in data_dir.glob('*')])) # create a list of class_names from subdirectories
print(class_names)
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random

def view_random_image(target_dir, target_class):
  # setup target directory
  target_folder = target_dir+target_class

  # get a random image path
  random_image = random.sample(os.listdir(target_folder), 1)

  # read the image and plot it
  img = mpimg.imread(target_folder + "/" + random_image[0])
  plt.imshow(img)
  plt.title(target_class)
  plt.axis("off")

  print(f"Image shape: {img.shape}") # the shape of the image

  return img
plt.figure()
plt.subplot(1,2,1)
pizza_img = view_random_image(target_dir="pizza_steak/train/",
                        target_class="pizza")

plt.subplot(1,2,2)
steak_img = view_random_image("pizza_steak/train/", "steak")
pizza_img
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# setup the train and test directory paths
train_dir = "pizza_steak/train/"
test_dir = "pizza_steak/test/"

# import data from directories and turn it into batches
train_data = train_datagen.flow_from_directory(train_dir,
                                               batch_size=32, # number of images to process at a time
                                               target_size=(224,224), 
                                               class_mode="binary")

test_data = test_datagen.flow_from_directory(test_dir,
                                               batch_size=32,
                                               target_size=(224,224),
                                               class_mode="binary")
images, labels = train_data.next()
len(images), len(labels)

# view the first batch of labels
labels
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation
from tensorflow.keras import Sequential

model_2 = Sequential([
              Conv2D(filters=10,
                     kernel_size=3,
                     strides=1,
                     padding="valid",
                     activation="relu",
                     input_shape=(224,224,3)), # input layer
              Conv2D(10,3, activation="relu"),
              Conv2D(10,3, activation="relu"),
              Flatten(),
              Dense(1, activation="sigmoid") 
])
model_2.compile(loss="binary_crossentropy",
                optimizer=Adam(),
                metrics=["accuracy"])
     

# check the length of training and testing data generators
len(train_data), len(test_data)
history_2 = model_2.fit(train_data,
                        epochs=1,
                        steps_per_epoch=len(train_data),
                        validation_data=test_data,
                        validation_steps=len(test_data))